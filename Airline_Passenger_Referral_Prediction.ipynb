{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - IndiGo Airline Passenger Referral Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Air travel has dramatically transformed the landscape of global connectivity, standing out as one of the most significant breakthroughs of the twentieth century. Its defining characteristic, speed, has rendered it an essential mode of transport for both individuals and goods.\n",
        "\n",
        "In the ever-evolving realm of aviation, passenger experience plays a pivotal role in determining success. The capacity to forecast passenger endorsements and recommendations has emerged as a strategic necessity for airlines. Gaining insights into which passengers are inclined to recommend an airline to their social circles can be a transformative factor in boosting customer satisfaction and driving revenue growth.\n",
        "\n",
        "Work Flow:-\n",
        "- Data Collection\n",
        "- Data Cleaning & Preprocessing:- This includes handling missing value, outliers treatment target encoding & feature enginnering.\n",
        "- Exploratory Data Analysis (EDA):- This include visualization of the data using various graphs & plots.\n",
        "- Splitting the Data into training & testing part\n",
        "- Model Selection and Hyperparameter Tuning:-To develop an accurate prediction system, a diverse array of classification models is employed. These models include Logistic Regression,Random Forests, & Support Vector Machines (SVM). Ensuring model reliability, hyperparameter tuning is performed to optimize performance and mitigate overfitting.\n",
        "- Evaluation Metrics:-The core focus of the analysis is on classification metrics, with Recall as the highest priority. Accuracy and ROC AUC follow closely behind. These metrics gauge the models' ability to correctly identify passengers who recommend airlines, crucial for targeting customer engagement efforts effectively."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/tanveermohd/Indigo-Airline-Passenger-Referral-Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the fast-paced and fiercely competitive world of aviation, customer satisfaction and loyalty are key determinants of an airlineâ€™s success. Airlines are perpetually exploring novel methods to elevate passenger experiences and bolster their brand image. A crucial element in realizing these goals is the capability to foresee which passengers are prone to endorse the airline within their social circles.\n",
        "\n",
        "The challenge we face involves the creation of a predictive model that can precisely pinpoint passengers who are likely to advocate for the airline. This predictive model will act as a strategic instrument for airlines to:\n",
        "\n",
        "1.Enhance their customer service by focusing on passengers who are potential advocates.\n",
        "\n",
        "2.Tailor their marketing and loyalty programs towards passengers who are more likely to recommend their services.\n",
        "\n",
        "3.Improve their overall brand reputation by increasing the number of positive referrals.\n",
        "\n",
        "4.Make informed business decisions based on the insights derived from the model.\n",
        "\n",
        "5.Ultimately, drive revenue growth by converting satisfied passengers into brand advocates.\n",
        "\n",
        "-Enhance Customer Satisfaction\n",
        "\n",
        "-Drive Revenue Growth\n",
        "\n",
        "-Optimize Marketing Efforts\n",
        "\n",
        "-Improve Service Quality\n",
        "\n",
        "-Gain a Competitive Edge"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# Importing all models from sklearn to be used in model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Importing  metrics for evaluation of models\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,precision_score\n",
        "from sklearn.metrics import recall_score,f1_score,roc_curve, roc_auc_score"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ff0rSXUX99AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Indigo airline referral prediction/data_airline_reviews.xlsx - capstone_airline_reviews3.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing=df.isnull().sum()\n",
        "missing"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "columns_with_missing_values = missing[missing > 0]\n",
        "len(columns_with_missing_values)\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of missing values in each column\n",
        "total_rows = len(df)\n",
        "percentage_missing = (columns_with_missing_values / total_rows) * 100\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(14, 6))\n",
        "bar_plot = columns_with_missing_values.plot(kind='bar', color='coral')\n",
        "plt.xlabel('Columns',fontsize=14)\n",
        "plt.ylabel('Number of Missing Values',fontsize=14)\n",
        "plt.title('Number of Missing Values in Columns',fontsize=14)\n",
        "plt.xticks(rotation=90, ha='center',fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the percentage of missing values on top of each bar\n",
        "for index, value in enumerate(columns_with_missing_values):\n",
        "    plt.text(index, value, f'{percentage_missing[index]:.2f}%', ha='center', va='bottom',fontsize=10)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JQ3mlSF3BVAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is well-prepared for further analysis, as it contains 131895 rows and 17 features. There are some missing values in every feature, which need to be fixed either by using the fillna method or dropping the rows. Additionally, there are 70711 duplicate rows, which also need to be dropped so that there is a clean and unique dataset for analysis. Most of the features are either objects or floats. If necessary, it needs to be converted into the required datatype. After the necessary cleaning, the dataset will be ready for preprocessing steps, allowing the focus to be on feature engineering and model development to achieve accurate predictions."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "airline: Name of the airline.\n",
        "\n",
        "overall: Overall point is given to the trip between 1 to 10.\n",
        "\n",
        "author: Author of the trip\n",
        "\n",
        "review date: Date of the Review\n",
        "\n",
        "customer review:Review of the customers in free text format\n",
        "\n",
        "aircraft: Type of the aircraft\n",
        "\n",
        "traveller type: Type of traveler (e.g. business, leisure)\n",
        "\n",
        "cabin: Cabin at the flight\n",
        "\n",
        "date flown: Flight date\n",
        "\n",
        "seat comfort: Rated between 1-5\n",
        "\n",
        "cabin service: Rated between 1-5\n",
        "\n",
        "foodbev: Rated between 1-5\n",
        "\n",
        "entertainment: Rated between 1-5\n",
        "\n",
        "ground service: Rated between 1-5\n",
        "\n",
        "value for money: Rated between 1-5\n",
        "\n",
        "recommended: Binary, target variable."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Dropping the column with more than 80 % empty columns\n",
        "df = df.drop(columns='aircraft',axis=1)\n",
        "\n",
        "#droping the duplicate values\n",
        "df.drop_duplicates(inplace = True)\n",
        "\n",
        "# Remove ordinal suffixes using regex\n",
        "df['review_date'] = df['review_date'].str.replace(r'(\\d+)(st|nd|rd|th)', r'\\1', regex=True)\n",
        "\n",
        "# Convert the \"review_date\" & \"date_flown\" column from object to datetime data type\n",
        "df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "df['date_flown'] = pd.to_datetime(df['date_flown'],errors='coerce')\n",
        "\n",
        "# Extract the year from the \"date_flown\" column and create a new column \"year\"\n",
        "df['year'] = df['date_flown'].dt.year\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "WjEPrUhxNKj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The column \"aircraft\" has more than 80% of the missing values. Hence, this column is removed. After that, the duplicated rows are deleted. These two cleaning processes reduce some of the missing entries. The datatype of the \"review date\" and \"date_flown\" columns is incorrect & hence changed to the datetime datatype. A new column for year has been created from the \"date_flown\" column."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 Check the dataset (balance or imbalance)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['recommended'].value_counts()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_percentage = df['recommended'].value_counts(normalize=True)*100\n",
        "count_percentage"
      ],
      "metadata": {
        "id": "tdRGLbtD5OSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "palette = sns.color_palette()\n",
        "\n",
        "# Create a countplot of the 'recommended' data\n",
        "sns.countplot(x=df['recommended'], palette='muted')\n",
        "\n",
        "# Set the x-axis label\n",
        "plt.xlabel('Recommended', fontsize=14)\n",
        "\n",
        "# Set the y-axis label\n",
        "plt.ylabel('Total counts', fontsize=14)\n",
        "\n",
        "# Set the title of the plot\n",
        "plt.title('Recommendation Status', fontsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wqKrcCJN5tO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot allows for a direct visual comparison of the counts of \"Yes\" and \"No\" recommendations. By using a single plot, we can easily compare the frequencies of these two categories."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is balanced, the distribution suggest that around 48% of customers are satisfied customer that recommended airline and 52% of customer are unhappy and didn't recommend the airline to other people."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n"
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plot showing recommendation frequency can have both positive and potentially negative impacts on a business, depending on how they are interpreted and acted upon."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 Checking the distribution of traveller types"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traveller_type_counts=df['traveller_type'].value_counts()\n",
        "traveller_type_counts"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pie chart\n",
        "plt.figure(figsize=(4, 4))\n",
        "# Create the pie chart with the explode effect and a shadow\n",
        "labels = traveller_type_counts.index\n",
        "sizes =traveller_type_counts.values\n",
        "explode = [0.1]*len(sizes)\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', explode=explode, shadow=True ,startangle=140,)\n",
        "plt.title('Distribution of Traveller Types')\n",
        "plt.axis('equal')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8dneIvGVJvHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"traveller_type\" column contains categorical data, which means it consists of distinct categories or labels (e.g., \"Business,\" \"Leisure\"). Pie-chart are particularly useful for visualizing the distribution of categorical data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bigger sector in the pie-chart represent the most frequently occurring traveler types. This can help us identify dominant or prevalent traveler types in the dataset.\n",
        "\n",
        "\"Solo Travellers\" constitue 37.1% of overall travellers type & contribute the biggest share in pie-chart followed by \"Couple Travellers\" which constitue 25.8% of overall travellers type.\n",
        "\n",
        "Business Travellers has the smallest share in travellers type distribution pie-chart."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 distribution of Cabin type based on recommended or not"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cabin'].value_counts()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x='cabin', hue='recommended', palette='Set2')\n",
        "plt.title('Distribution of Recommended by Cabin', fontsize=14)\n",
        "plt.xlabel('Cabin', fontsize=14)\n",
        "plt.ylabel('Count',fontsize=14)\n",
        "plt.legend(title='Recommended', labels=['Yes', 'No'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MIc_2neFMFJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot with the hue parameter is an effective choice when we want to compare the distribution of a binary variable (such as \"recommended\") within different categories (in this case, \"cabin\" types). It allows for clear visualization and comparison, which can lead to insights about customer preferences and recommendations across cabin types."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights variations in the distribution of recommendations across different cabin types. For instance-\n",
        "\n",
        "In the \"Economy\" cabin, there are both more recommendations and more non-recommendations compared to other cabins.\n",
        "\n",
        "In contrast, \"Business class\" and \"First class\" cabin passengers seem to have a higher rate of recommendations compared to non-recommendations."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Targeted Marketing: The insights can inform targeted marketing strategies. Airlines can focus their marketing efforts on promoting the features and benefits of cabin types that receive high recommendations, attracting more customers to those premium offerings.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Missed Revenue Opportunities: Ignoring insights about low recommendation rates may result in missed revenue opportunities. By not addressing passenger concerns and improving services in underperforming cabins, airlines may lose potential revenue from dissatisfied customers."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 Value for Money Across Different Traveler Types"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a barplot with the 'Set1' color palette\n",
        "sns.barplot(x='traveller_type', y='value_for_money', data=df, palette='Set2')\n",
        "\n",
        "plt.title('Value for Money by Traveler Type',fontsize=14)\n",
        "plt.xlabel('Traveller Type',fontsize=14)\n",
        "plt.ylabel('Value for Money',fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are easy to understand. They display discrete categories on the x-axis and the numerical variable on the y-axis, making it straightforward for viewers to interpret the data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how different traveller types rate the \"value_for_money\" aspect of the airline service.\n",
        "\n",
        "The Solo Traveller have given highest rating for \"Value For Money\" while there are almost equal rating given by rest of the traveller.\n",
        "This can help identify which traveller type, such as business travellers, leisure travellers, or others, find the service to be of better value."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impacts:\n",
        "\n",
        "Service Improvement: By identifying traveller types with lower ratings for \"value_for_money,\" the airline can investigate why these travelers feel this way. This feedback can guide improvements in pricing, amenities, or services to enhance customer satisfaction.\n",
        "\n",
        "Negative Business Impacts:\n",
        "\n",
        "Customer Churn: If certain traveller types consistently rate the airline's \"value_for_money\" poorly and these issues are not"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 Airline Seat Comfort Ratings: Top Airlines for Passenger Comfort"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['airline'].value_counts()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['airline'].nunique()"
      ],
      "metadata": {
        "id": "Gbc-sRa3E3ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average of seat comfort rating for each airline\n",
        "avg_seat_comfort = df.groupby('airline')['seat_comfort'].mean().reset_index()\n",
        "\n",
        "# Sort the DataFrame by average seat comfort ratings in descending order\n",
        "avg_seat_comfort_sorted = avg_seat_comfort.sort_values(by='seat_comfort', ascending=False)\n",
        "print(avg_seat_comfort_sorted)"
      ],
      "metadata": {
        "id": "Xx8ODv-JE9Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create a barplot\n",
        "sns.barplot(x='airline', y='seat_comfort', data=avg_seat_comfort_sorted, palette='viridis')\n",
        "\n",
        "plt.xticks(rotation=90, fontsize=10)\n",
        "plt.xlabel('Airline', fontsize=10)\n",
        "plt.ylabel('Seat Comfort Rating', fontsize=14)\n",
        "plt.title('Seat Comfort Rating by Airline', fontsize=14)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U_-0EEYKFFDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are effective for comparing the values of a single variable (in this case, \"seat_comfort\" ratings) across different categories (airlines). They allow you to easily see and compare how the ratings vary for each airline."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Seat Comfort rating of some airlines, such as \"Air Canada\", \"Frontier Airlines,\" and \"Spirit Airlines,\" is very poor compared to the average rating of all other airlines. While some airlines, such as \"Asiana Airline\",\"EVA Air\", \"China Southern Airlines,\" and \"Garuda Airlines, are rated the best compared to other airlines."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Pricing Strategies: Airlines with exceptional seat comfort may have the opportunity to position themselves as premium carriers and charge higher ticket prices. Passengers may be willing to pay more for increased comfort, leading to higher revenue per passenger.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Customer Churn: Airlines with consistently low seat comfort ratings may experience customer churn as passengers opt for competitors with better comfort offerings. This can lead to a loss of revenue and market share."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 Average Cabin Service Ratings by Airline"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average cabin service rating for each airline\n",
        "avg_seat_comfort = df.groupby('airline')['cabin_service'].mean().reset_index()\n",
        "\n",
        "# Sort the DataFrame by average seat comfort ratings in descending order\n",
        "avg_seat_comfort_sorted = avg_seat_comfort.sort_values(by='cabin_service', ascending=False)\n",
        "print(avg_seat_comfort_sorted)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='airline', y='cabin_service', data=avg_seat_comfort_sorted, palette='viridis')\n",
        "\n",
        "plt.xticks(rotation=90, fontsize=10)\n",
        "plt.xlabel('Airline', fontsize=14)\n",
        "plt.ylabel('Cabin Service Rating', fontsize=14)\n",
        "plt.title('Cabin Service Rating by Airline', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MvB0oD_HF7By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts are commonly used to display and compare data for different categories. It allows for easy comparison between different airlines' cabin service ratings. The bars make it straightforward to see which airlines have higher or lower ratings."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart clearly shows that \"Garuda Indonesia\" \"\"Nippon Airways\" etc. have the highest cabin service ratings while \"Frontier Airlines\" & \"Spirit Airlines\" have the lowest cabin service ratings. This allows viewers to quickly identify the best and worst performers airlines in terms of cabin service."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Competitive Advantage: Airlines with higher cabin service ratings can leverage this information to promote their superior service in marketing and advertising campaigns. This can attract more passengers who value quality service, potentially leading to increased market share and revenue.\n",
        "\n",
        "Negative Growth Potential:\n",
        "\n",
        "Inaction: One of the most significant potential negative impacts is inaction. If airlines do not address the issues highlighted by low cabin service ratings, they risk losing customers to competitors who offer better service. This can result in decreased revenue and market share."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 Average Food and Beverage Ratings by Airline"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average food beverages rating for each airline\n",
        "avg_seat_comfort = df.groupby('airline')['food_bev'].mean().reset_index()\n",
        "\n",
        "# Sort the DataFrame by average seat comfort ratings in descending order\n",
        "avg_seat_comfort_sorted = avg_seat_comfort.sort_values(by='food_bev', ascending=False)"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='airline', y='food_bev', data=avg_seat_comfort_sorted, palette='viridis')\n",
        "\n",
        "plt.xticks(rotation=90, fontsize=10)\n",
        "plt.xlabel('Airline', fontsize=12)\n",
        "plt.ylabel('Food Beverages Rating', fontsize=14)\n",
        "plt.title('Food Beverages Rating by Airline', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kXO851YWH4kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is an excellent choice when we want to compare the values of a categorical variable (airlines) with respect to a continuous variable (food and beverage ratings). It allows viewers to quickly discern differences in ratings between airlines."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart clearly shows that \"Garuda Indonesia\" \"\"Nippon Airways\" & \"Asiana Airlines\" etc. have the highest food beverages rating while \"Frontier Airlines\" & \"Spirit Airlines\" have the lowest food beverages ratings. This allows viewers to quickly identify the best and worst performers airlines in terms of Food & Beverages Services."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Revenue Growth: Positive ratings can lead to higher revenue through increased ticket sales and potentially higher spending by passengers on in-flight dining options.\n",
        "\n",
        "Brand Reputation: High ratings contribute to a positive brand reputation, which can lead to brand loyalty and the attraction of new customers.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Reduced Revenue: Low ratings can deter passengers from purchasing in-flight meals or snacks, resulting in reduced revenue from onboard sales.\n",
        "\n",
        "Negative Publicity: Negative feedback about food and beverages on social media or review platforms can harm an airline's image and result in negative publicity."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 Recommendation Count per Airline"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the recommendation count per airline\n",
        "recommendation_counts = df.groupby(['airline', 'recommended']).size().unstack(fill_value=0)\n",
        "\n",
        "# Reset the index\n",
        "recommendation_counts.reset_index(inplace=True)\n",
        "\n",
        "# Rename the columns\n",
        "recommendation_counts.columns = ['Airline', 'No', 'Yes']\n",
        "\n",
        "print(recommendation_counts)"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='airline', hue='recommended', data=df,palette='Set2')\n",
        "plt.xticks(rotation=90,fontsize=10)\n",
        "plt.xlabel('Airline',fontsize=12)\n",
        "plt.ylabel('Count',fontsize=16)\n",
        "plt.title('Recommendation Count per Airline',fontsize=16)\n",
        "plt.legend(title='Recommended')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hOkEJemjJBGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot allows for a direct visual comparison of recommendation counts across multiple airlines. By using the hue parameter to differentiate between \"Yes\" and \"No\" recommendations, it's easy to assess the distribution of recommendations for each airline."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qatar Airlines, Singapore Airlines, China Southern Airlines, Garuda Airlines & Qantas Airlines have a higher count of \"Yes\" recommendations. These airlines are likely providing a positive experience to passengers, leading to more recommendations.whereas, American Airlines, United Airlines, Spirit Airlines & Frontier Airlines have a higher count of \"No\" recommendations. These airlines may have areas for improvement in their services or customer satisfaction."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Customer Loyalty: Airlines with higher counts of \"Yes\" recommendations have the potential to build strong customer loyalty. This can lead to repeat business, positive word-of-mouth recommendations, and an increase in customer lifetime value.\n",
        "\n",
        "Strategic Decision-Making: Airlines can use these insights to make informed strategic decisions, such as investing in service enhancements, training staff, or upgrading amenities to meet passenger expectations.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Customer Churn: Airlines with consistently high counts of \"No\" recommendations may experience customer churn. Passengers may choose competitors with better ratings, leading to a loss of revenue and market share.\n",
        "\n",
        "Reputation Damage: Persistently poor recommendation counts can harm an airline's reputation. Negative reviews and low recommendations can deter potential customers and erode trust in the brand."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 Average Ratings of Services by Cabin Type"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# Calculate the average ratings for 'seat_comfort','cabin_service','food_bev', 'entertainment','ground_service' by cabin\n",
        "average_ratings = df.groupby('cabin')[['seat_comfort','cabin_service','food_bev', 'entertainment','ground_service']].mean().reset_index()\n",
        "\n",
        "# Set the figure size\n",
        "plt.rcParams['figure.figsize']=(8,6)\n",
        "\n",
        "# Define the color list for the bars\n",
        "colors = ['b', 'g', 'r', 'c', 'm']\n",
        "\n",
        "# Plot the data\n",
        "average_ratings.plot(x=\"cabin\", y=['seat_comfort','cabin_service','food_bev', 'entertainment','ground_service'], kind=\"bar\", color=colors, fontsize=12)\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel(\"Cabin Type\",fontsize=15)\n",
        "plt.ylabel(\"Average Ratings by Cabin Type\",fontsize=15)\n",
        "plt.title(\"Average Ratings for Different Cabin Types\", fontsize=18)\n",
        "\n",
        "# Set legend\n",
        "plt.legend([\"Seat Comfort\", \"Cabin Service\", \"Food & Beverage\", \"Entertainment\", \"Ground Service\"], fontsize=12)\n",
        "\n",
        "# Rotate x-axis labels\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A grouped bar chart is an effective way to compare and visualize the average ratings of different factors for each cabin type. Each factor is represented by a distinct bar, and the bars are grouped by cabin type. This clear differentiation makes it easy to identify and compare ratings for each factor within each cabin type."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average rating of all services types for Business Class as well as First Class cabin type is best.\n",
        "Economy Class is worst rated in all the service types."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Marketing and Pricing Strategies: Understanding which cabin types receive higher ratings for specific categories enables the airline to target marketing efforts more effectively. They can promote the strengths of certain cabins and tailor pricing strategies to appeal to different customer preferences.\n",
        "\n",
        "Negative Growth or Concerns:\n",
        "\n",
        "Operational Challenges: Insights into lower ratings for specific services or cabin types may signal operational challenges that need immediate attention. Failure to address these issues could result in negative growth as passengers seek better experiences elsewhere."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 Overall Rating by Passenger vs. Airline"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.set_style(\"whitegrid\")  # Set style to whitegrid for better readability\n",
        "sns.lineplot(x='airline', y='overall', data=df, marker='o', markersize=5, color='darkblue', markerfacecolor='red',linewidth=3)\n",
        "\n",
        "plt.xlabel('Airline', fontsize=15)\n",
        "plt.ylabel('Overall Rating by Passenger', fontsize=14)\n",
        "plt.title('Overall Rating of Airline', fontsize=12)\n",
        "plt.xticks(rotation=90, fontsize=10)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Line plots are excellent for showing continuous trends or patterns in data. They connect data points with lines, making it easier to identify trends or fluctuations over time."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly observe that \"Garuda Airlines\",\"Asiana Airline\" & \"EVA Air\" have the highest overall rating while \"Frontier Airlines\", \"Spirit Airlines\",\"American Airlines\" & \"Delta Airlines\" are worst rated airlines."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Identification of Top-Rated Airlines: Airlines with higher ratings can use this information to market themselves as customer favorites and attract more passengers. They can can leverage their positive reputation to gain a competitive advantage in the market. This can lead to increased market share and revenue growth.\n",
        "\n",
        "Potential Negative Growth:\n",
        "\n",
        "Customer Attrition: Passengers dissatisfied with low-rated airlines may choose alternative modes of transportation or opt for competitors, resulting in customer attrition and revenue loss. These Airlines may struggle with operational challenges, including increased customer complaints, regulatory scrutiny, and employee morale issues."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 Change in overall review over succeeding year for top 12 airlines"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Calculate the average overall rating for each airline\n",
        "average_overall_rating = df.groupby('airline')['overall'].mean().reset_index()\n",
        "\n",
        "# Sort by average overall rating and select the top 12 airlines\n",
        "top_12_airlines = average_overall_rating.nlargest(12, 'overall')['airline']\n",
        "\n",
        "# Filter the DataFrame to include only data for the top 12 airlines\n",
        "filtered_df = df[df['airline'].isin(top_12_airlines)]\n",
        "\n",
        "# Create a FacetGrid with subplots for each airline\n",
        "g = sns.FacetGrid(filtered_df, col='airline', col_wrap=4, height=4, aspect=0.7, hue='airline', palette='Set1')\n",
        "g.map(sns.lineplot, 'year', 'overall', marker='o', lw=2)\n",
        "\n",
        "# Set axis labels and titles\n",
        "g.set_axis_labels('Year', 'Overall Rating', fontsize=16)\n",
        "g.set_titles(col_template='{col_name}')\n",
        "\n",
        "# Adjust subplot spacing and add a title at the top\n",
        "plt.subplots_adjust(top=0.85)\n",
        "plt.suptitle('Overall Rating Over Succeeding Years for Top 12 Airlines', fontsize=16)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plots are well-suited for time-series data, which involves tracking data points over successive time periods. This makes it suitable for analyzing how overall rating changes over time."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart aids in competitive analysis by showing how each airline's overall rating compares to its peers.\n",
        "\n",
        "Airlines with consistently high ratings may have a competitive advantage. For example \"China Southern Airlines\" & \"Garuda Airlines\".\n",
        "\n",
        "Sudden drops or spikes in overall ratings may indicate shifts in customer sentiment.For example \"Aegean Airlines\"."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Identifying Improvement Areas: Insights that highlight consistent upward trends in overall ratings can help airlines identify areas where they are excelling. They can leverage these strengths in marketing efforts to attract more customers who prioritize those aspects.\n",
        "\n",
        "Potential Negative Growth:\n",
        "\n",
        "Ignoring Negative Trends: Failing to address consistent negative trends in overall ratings can lead to a decline in customer satisfaction and negative growth. If airlines do not respond to customer feedback and complaints, they risk losing customers to competitors.\n",
        "\n",
        "Competitive Disadvantage: Airlines with consistently low ratings may find it challenging to compete in the market. Negative feedback can deter potential customers, leading to decreased market share."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "df_numeric = df.select_dtypes(include=['number'])\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(df_numeric.corr(), annot=True,cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps are particularly effective for visualizing correlation between variables."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the heatmap it is clearly visible that all the independent variables are strongly correlated with each other. Hence, during further data preprocessing we need to take care of multicollinearity."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 15 Pair Plot visualization code\n",
        "columns = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "plt.figure(figsize=(8,4))\n",
        "# Create a pairplot\n",
        "sns.pairplot(df[columns])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplots allow us to visualize multivariate relationships in a dataset. It help us to identify patterns, trends, and relationships between variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since all the variables are discrete in nature, it is not possible to reach any conclusion without further data analysis."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 Airline passengers who rate seat comfort higher are more likely to recommend the airline.\n",
        "- 2 Reviews posted in recent years are more critical of airline services compared to reviews from earlier years.\n",
        "- 3 Passengers who travel for business purposes rate cabin service higher than those traveling for leisure."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1  Airline passengers who rate seat comfort higher are more likely to recommend the airline."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant correlation between seat comfort ratings and the likelihood of recommending the airline.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant correlation between seat comfort ratings and the likelihood of recommending the airline."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Dropping the Null Value from the \"recommended\" & \"seat_comfort\" column\n",
        "recommended=df['recommended'].dropna()\n",
        "seat_comfort=df['seat_comfort'].dropna()\n",
        "\n",
        "# Convert the data in 'recommended' columns to numeric\n",
        "recommended=recommended.replace({'yes': 1, 'no': 0})\n",
        "\n",
        "# Picking out 100 Random Samples to perform t-test\n",
        "sample_recommended=recommended.sample(100,random_state=42)\n",
        "sample_seat_comfort=seat_comfort.sample(100,random_state=42)\n",
        "\n",
        "# Perform t-test\n",
        "t_statistic, p_value = stats.ttest_ind(sample_seat_comfort, sample_recommended)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Compare p-value with alpha to make a decision\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in seat comfort ratings.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in seat comfort ratings.\")\n",
        ""
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2 Reviews posted in recent years are more critical of airline services compared to reviews from earlier years."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the average overall ratings of airline reviews posted in recent years compared to reviews from earlier years.\n",
        "\n",
        "Alternative Hypothesis (H1): Reviews posted in recent years have significantly lower average overall ratings compared to reviews from earlier years."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Define a threshold year to distinguish recent and earlier years\n",
        "threshold_year = 2019\n",
        "\n",
        "# Split the data into two groups: recent and earlier years\n",
        "recent_years = df[df['year'] >= threshold_year]['overall']\n",
        "earlier_years = df[df['year'] < threshold_year]['overall']\n",
        "\n",
        "# Dropping the null value\n",
        "recent_years=recent_years.dropna()\n",
        "earlier_years=earlier_years.dropna()\n",
        "\n",
        "# Picking 100 random samples to perform t-test\n",
        "random_recent_years=recent_years.sample(100,random_state=42)\n",
        "random_earlier_years=earlier_years.sample(100,random_state=42)\n",
        "\n",
        "# Perform a t-test to compare the average overall ratings\n",
        "t_statistic, p_value = stats.ttest_ind(random_recent_years, random_earlier_years)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Compare p-value with alpha to make a decision\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Reviews from recent years are more critical of airline services compared to reviews from earlier years.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in review ratings between recent and earlier years.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test are performed to find P-value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3 Passengers who travel for business purposes rate cabin service higher than those traveling for leisure."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in the average cabin service ratings between passengers who travel for business purposes and those who travel for leisure.\n",
        "\n",
        "Alternative Hypothesis (H1): Passengers who travel for business purposes rate cabin service significantly higher than passengers who travel for leisure."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Convert 'traveller_type' column to lowercase for consistency\n",
        "df['traveller_type'] = df['traveller_type'].str.lower()\n",
        "\n",
        "# Define the two groups: business travelers and leisure travelers\n",
        "business_travelers = df[df['traveller_type'] == 'business']['cabin_service']\n",
        "leisure_travelers = df[df['traveller_type'] !='business']['cabin_service']\n",
        "\n",
        "# Dropping the Null Value from\n",
        "business_travelers=business_travelers.dropna()\n",
        "leisure_travelers=leisure_travelers.dropna()\n",
        "\n",
        "# Picking 100 random samples to perform t-test\n",
        "sample_business_travelers=business_travelers.sample(100,random_state=42)\n",
        "sample_couple_travelers=leisure_travelers.sample(100,random_state=42)\n",
        "\n",
        "# Perform a t-test to compare the average cabin service ratings\n",
        "t_statistic, p_value = stats.ttest_ind(sample_business_travelers, sample_couple_travelers)\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Compare p-value with alpha to make a decision\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. Business travelers rate cabin service higher than leisure travelers.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in cabin service ratings between business and leisure travelers.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making copy of original dataframe\n",
        "df1=df.copy()\n",
        "# take useful columns\n",
        "df1 = df[['overall','traveller_type', 'cabin','seat_comfort','cabin_service', 'food_bev',\n",
        "               'entertainment', 'ground_service','value_for_money', 'recommended']]"
      ],
      "metadata": {
        "id": "aeAFPZ4rku8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "jsAR8gzekun9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "bYnVlNbhlIkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Imputing numerical column with mean using Sklearn Simple Imputer method\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Columns to impute\n",
        "numeric_column=['overall', 'seat_comfort', 'cabin_service','food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "categorical_column=['traveller_type', 'cabin']\n",
        "\n",
        "# Create instance of Simple Imputer with mean strategy\n",
        "numeric_imputer=SimpleImputer(strategy='mean')\n",
        "categorical_imputer=SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Fitting the imputer method\n",
        "df1[numeric_column]=numeric_imputer.fit_transform(df1[numeric_column])\n",
        "df1[categorical_column]=categorical_imputer.fit_transform(df1[categorical_column])\n",
        "\n",
        "# Applying dropna() method on target variable\n",
        "df1.dropna(subset='recommended',inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.isnull().sum()"
      ],
      "metadata": {
        "id": "htlLFWl4mCCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.duplicated().sum()"
      ],
      "metadata": {
        "id": "fFLbbUAXmJ5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "A0R5eQjLmPOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop_duplicates(inplace=True)\n",
        "df1.duplicated().sum()"
      ],
      "metadata": {
        "id": "mVk2nGD9mYe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean imputation technique is used on numerical columns while mode imputation technique is used on categorical columns.\n",
        "\n",
        "Mean imputation is appropriate when we want to maintain the central tendency of the data.\n",
        "\n",
        "Mode imputation is suitable for categorical data as it preserves the most common category.\n",
        "\n",
        "The Target column(\"recommended\") is imputed using dropna technique because using mode imputation on target column will lead to Class Imbalance."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.boxplot(df1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no need to address outliers because there are no outliers in the independent variables."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Binary Encoding Target Variable\n",
        "df1['recommended']=df1['recommended'].replace({'yes': 1, 'no': 0})\n",
        "\n",
        "# Applying Ordinal Encoding to cabin column\n",
        "df1['cabin']=df1['cabin'].replace({'Economy Class':0, 'Premium Economy':1, 'Business Class' : 2,'First Class':3})\n",
        "\n",
        "# Applying One Hot Encoding to Traveller_Type column\n",
        "ohe=pd.get_dummies(df1['traveller_type'],drop_first=True)\n",
        "\n",
        "# Concatenating the encoded feature with original dataframe\n",
        "df1=pd.concat([df1,ohe],axis=1)\n",
        "\n",
        "# Dropping traveller_type column from the dataframe\n",
        "df1=df1.drop('traveller_type',axis=1)\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "D2uiEp6pn0Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Encoding for Target Variable:-This is often done when we have a binary classification problem, where you want to predict one of two classes.This code is converting the 'recommended' column with values 'yes' and 'no,' into numerical values 'yes' is being encoded as 1, and 'no' as 0.\n",
        "\n",
        "Ordinal Encoding for 'cabin' Column:-Ordinal encoding is suitable when there is an inherent order or ranking among the categories. Different cabin classes ('Economy Class,' 'Premium Economy,' 'Business Class,' 'First Class') are being mapped to integer values (0, 1, 2, 3).\n",
        "\n",
        "One-Hot Encoding for 'traveller_type' Column:- One-hot encoding is suitable for the those categorical column with no intrinsic order. One-hot encoding creates binary (0 or 1) columns for each category, indicating whether each instance belongs to that category or not. The drop_first=True argument is specified to drop one of the one-hot-encoded columns to prevent multicollinearity.\n",
        "\n"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# Checking Multicollinearity\n",
        "\n",
        "def calculate_vif(X):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['Features'] = X.columns\n",
        "    vif['VIF'] = [round(variance_inflation_factor(X.values, i),2) for i in range(X.shape[1])]\n",
        "    return vif\n",
        "\n",
        "# Select columns for which VIF is calculated\n",
        "selected_columns = [col for col in df1.describe().columns if col not in ['recommended']]\n",
        "\n",
        "# Selecting the columns from DataFrame\n",
        "selected_data = df1[selected_columns]\n",
        "\n",
        "# Calculate VIF for the selected columns\n",
        "vif_result = calculate_vif(selected_data)\n",
        "\n",
        "# Sort the VIF result DataFrame by VIF in descending order\n",
        "vif_result_sorted = vif_result.sort_values(by='VIF', ascending=False)\n",
        "\n",
        "print(vif_result_sorted)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Identify columns with high VIF\n",
        "high_vif_cols = vif_result[vif_result['VIF'] > 12]['Features']\n",
        "\n",
        "# Remove columns with high VIF\n",
        "df1.drop(high_vif_cols, axis=1, inplace=True)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variance Inflation Factor method is used for feature selection.\n",
        "\n",
        "VIF is used to identify and potentially remove features that contribute to multicollinearity. The idea is to retain a subset of features that are relatively independent of each other, reducing the negative effects of multicollinearity.\n",
        "\n",
        "High VIF values suggest that a feature can be predicted using the other features, and therefore it might be redundant in the presence of other correlated features."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a multivariate regression model, multicollinearity exists when there is a correlation betweem many independent variables. Under ideal conditions, small VIF value suggest low correlation accross variables. Hence keeping the threshold limit of 12, all the variables with VIF< 12 is included in the model."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.skew()"
      ],
      "metadata": {
        "id": "V2v9UZdYpVHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Need to Transform the data as the data is almost symmetrical in nature. The skewness which is shown in \"Cabin\",\"couple leisure\" & \"family leisure\" becuase they are encoded data."
      ],
      "metadata": {
        "id": "_Dkstwf1pn0u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Normalizing data using MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "scaled_df = pd.DataFrame(sc.fit_transform(df1))\n",
        "scaled_df.columns = df1.columns\n",
        "scaled_df.head()"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "MinMax scaling is used to scale the data.\n",
        "\n",
        "During the outlier removal step, some of the outliers remain with the data, and hence, to reduce the effect of outliers, MinMax scaling is the best scaling technique. It compressed the whole data into the range of 0 to 1."
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality reduction techniques can lead to information loss. Since we have only 10 features in our dataset, the risk of overfitting is reduced because the model has fewer opportunities to fit noise in the data. Hence no need to apply dimensionality reduction techniques such as PCA."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "X=scaled_df.drop('recommended',axis=1)\n",
        "y=scaled_df['recommended']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.20,random_state=10)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "T5FY_kiArMAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is split in the ratio of 80:20 which means 80% of the data is used for training purpose & remaining 20% data is used for testing purpose.\n",
        "\n",
        "The choice of the train-test split ratio, such as 0.8 (80%) for training and 0.2 (20%) for testing, is not a strict rule, but rather a commonly used practice in machine learning and data analysis. This ratio is often chosen due to a balance between ensuring sufficient data for training a model while also having a sizable portion for evaluating its performance on unseen data."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['recommended'].value_counts()"
      ],
      "metadata": {
        "id": "6icE_AhRrXDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is not imbalanced & hence no need to balance it."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 (Logistic Regression)"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Applying Logistic Regression\n",
        "model_lr=LogisticRegression(fit_intercept=True, max_iter=1000)\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_lr.fit(X_train,y_train)\n",
        "# Predict on the model\n",
        "train_class_preds = model_lr.predict(X_train)\n",
        "test_class_preds = model_lr.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the accuracy scores\n",
        "train_accuracy = accuracy_score(train_class_preds,y_train)\n",
        "test_accuracy = accuracy_score(test_class_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)"
      ],
      "metadata": {
        "id": "eUg543FGsTNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing actual vs predicted value\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plotting the predicted values for the specific range\n",
        "plt.plot(test_class_preds[100:200], label=\"Predicted\", color='limegreen')\n",
        "\n",
        "# Plotting the actual values for the specific range\n",
        "plt.plot(np.array(y_test[100:200]), label=\"Actual\", color='black')\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Actual vs. Predicted Values (Logistic Regression)\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PUomg3NVsj1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix of Training Class\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_train_lr = confusion_matrix(y_train,train_class_preds)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_train_lr, annot=True, fmt = 'd',ax = ax,cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Training Class Data',fontsize=15)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "Kx6Szpfjsohc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix of Test Class\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_test_lr = confusion_matrix(y_test,test_class_preds)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_test_lr, annot=True, fmt = 'd',ax = ax,cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Test Class Data',fontsize=15)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "SuJ0a3oDsx-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Training Data\")\n",
        "print(classification_report(y_train, train_class_preds))\n",
        "print(\"\\n\")\n",
        "print(\"Testing Data\")\n",
        "print(classification_report(y_test, test_class_preds))"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a statistical and machine learning technique used for binary and multiclass classification tasks. It's commonly used for binary classification problems, where the target variable has two possible outcomes, often denoted as 0 (negative class) and 1 (positive class).\n",
        "\n",
        "Based on the above evaluation metric score chart, the Logistic Regression model demonstrates strong performance in both classifying instances as class 0 and class 1. It achieves a good balance between precision and recall for both classes and an overall accuracy of 85%, indicating its effectiveness in making accurate predictions for binary classification"
      ],
      "metadata": {
        "id": "Yd2XT7ndtFvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "logistic_param={'penalty': ['l1', 'l2', 'elasticnet', None],\n",
        "                'C':[0.01,0.1,1,5,10],\n",
        "                'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
        "                'l1_ratio':[0,0.4,0.6,0.8,1]}\n",
        "\n",
        "model_logistic=LogisticRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "logistic_grid = GridSearchCV(model_logistic, logistic_param, cv=5, scoring='roc_auc')\n",
        "\n",
        "logistic_grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logistic_grid.best_params_)\n",
        "print(logistic_grid.best_score_)\n",
        "\n",
        "# Predict on the model\n",
        "train_lr_preds = logistic_grid.predict(X_train)\n",
        "test_lr_preds = logistic_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "O7BdqPcatuRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the accuracy scores\n",
        "train_accuracy_lr = accuracy_score(train_lr_preds,y_train)\n",
        "test_accuracy_lr = accuracy_score(test_lr_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_lr)\n",
        "print(\"The accuracy on test data is \", test_accuracy_lr)"
      ],
      "metadata": {
        "id": "Tz0JXq96t8pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Applying Cross Validation on  Logistic Regression\n",
        "scores=cross_val_score(model_logistic,X_train,y_train,cv=10,scoring='roc_auc')\n",
        "cv_score=scores.mean()\n",
        "print(\"Cross Validation Score is: \",cv_score)"
      ],
      "metadata": {
        "id": "xUkxiOhSudqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GridSearchCV is used as hyperparameter optimisation. The reason is that it exhaustively explores a given hyperparameter space to identify the perfect hyperparameter that would produce the greatest model performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart after Hyperparameter Tuning\n",
        "print(\"Training Data\")\n",
        "print(classification_report(y_train, train_lr_preds))\n",
        "print(\"\\n\")\n",
        "print(\"Testing Data\")\n",
        "print(classification_report(y_test, test_lr_preds))"
      ],
      "metadata": {
        "id": "RnzLf0XwurH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As far as accuracy is concerned, there is no improvement after performing hyperparameter tuning, and it remains at 85%."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Random Forest Classifier"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Random Forest Regressor\n",
        "model_rf=RandomForestClassifier()\n",
        "\n",
        "# fit the model\n",
        "model_rf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "p3736aEBvRBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "train_preds_rf = model_rf.predict(X_train)\n",
        "test_preds_rf = model_rf.predict(X_test)"
      ],
      "metadata": {
        "id": "z6T1l-UPvZSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the accuracy scores\n",
        "train_rf_accuracy = accuracy_score(train_preds_rf,y_train)\n",
        "test_rf_accuracy = accuracy_score(test_preds_rf,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_rf_accuracy)\n",
        "print(\"The accuracy on test data is \", test_rf_accuracy)"
      ],
      "metadata": {
        "id": "ThzhpBvtvZx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing actual vs predicted value\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plotting the predicted values for the specific range\n",
        "plt.plot(test_preds_rf[100:200],label=\"Predicted\",color='limegreen')\n",
        "\n",
        "\n",
        "# Plotting the actual values for the specific range\n",
        "plt.plot(np.array(y_test[100:200]),label=\"Actual\",color='black')\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Actual vs. Predicted Values (Random Forest Classifier)\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pmYRFDGjvghu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix of Training Class\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_train_rf = confusion_matrix(y_train,train_preds_rf)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_train_rf, annot=True, fmt = 'd', ax = ax, cmap='coolwarm')  # Added 'cmap' parameter\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Training Class Data',fontsize=15)\n",
        "plt.show()  # Changed from plt.plot() to plt.show()\n"
      ],
      "metadata": {
        "id": "GUSXBeU_vmAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix of Testing Class\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_test_rf = confusion_matrix(y_test,test_preds_rf)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_test_rf, annot=True, fmt = 'd',ax = ax,cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Test Data',fontsize=15)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "TdBORqLzvlvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "print(\"Training Data\")\n",
        "print(classification_report(y_train, train_preds_rf))\n",
        "print(\"\\n\")\n",
        "print(\"Testing Data\")\n",
        "print(classification_report(y_test, test_preds_rf))"
      ],
      "metadata": {
        "id": "LvcPXevGvyaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwgLossUv1jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Classifier is an ensemble learning algorithm that combines multiple decision trees to make more accurate predictions. In a Random Forest, a random subset of the training data and a random subset of the input features are used to train each decision tree. This randomness helps reduce overfitting and increases the model's generalization ability. During classification, the algorithm aggregates the predictions of the individual trees and typically selects the majority class as the final prediction.\n",
        "\n",
        "From the evaluation metric score chart, we can clearly observe that the accuracy score has decreased to 82% from 85% calculated through the logistic regression model. However the Random Forest Model did good on training data (91%) compared to Logistic Regression Model (84%)."
      ],
      "metadata": {
        "id": "yVIYtfFtv_71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "max_features = [0.2,0.6,1.0]\n",
        "max_depth = [2,8,None]\n",
        "max_samples = [0.5,0.75,1.0]\n",
        "\n",
        "\n",
        "param_grid = {'max_features': max_features,\n",
        "              'max_depth': max_depth,\n",
        "            'max_samples':max_samples}\n",
        "# Fit the Algorithm\n",
        "model_rf = RandomForestClassifier()\n",
        "rf_grid = GridSearchCV(estimator = model_rf,\n",
        "                       param_grid = param_grid,\n",
        "                       cv = 3,\n",
        "                       verbose=2,\n",
        "                       n_jobs = -1)\n",
        "rf_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_grid.best_params_)\n",
        "print(rf_grid.best_score_)"
      ],
      "metadata": {
        "id": "lh5wVFhswMKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "train_tuned_rf_preds = rf_grid.predict(X_train)\n",
        "test_tuned_rf_preds = rf_grid.predict(X_test)\n",
        "# Get the accuracy scores\n",
        "train_accuracy_tuned_rf = accuracy_score(train_tuned_rf_preds,y_train)\n",
        "test_accuracy_tuned_rf = accuracy_score(test_tuned_rf_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_tuned_rf)\n",
        "print(\"The accuracy on test data is \", test_accuracy_tuned_rf)"
      ],
      "metadata": {
        "id": "1cSMj9RqwRer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Cross Validation on Random Forest Model\n",
        "scores=cross_val_score(model_rf,X_train,y_train,cv=10,scoring='roc_auc')\n",
        "cv_score=scores.mean()\n",
        "print(\"Cross Validation Score is: \",cv_score)"
      ],
      "metadata": {
        "id": "mvqgDV5twb9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GridSearchCV is used as hyperparameter optimisation. The reason is that it exhaustively explores a given hyperparameter space to identify the perfect hyperparameter that would produce the greatest model performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is slight increase in the testing accuracy after hyperparameter tuning. The accuracy score which was 82% without hyperparameter tuning increased to 85% after hyperparameter tuning.\n",
        "\n",
        "However one thing to note here is that the training accuracy which was 91% without tuning has decreased to 85%."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each evaluation metric in a machine learning model provides valuable insights into the model's performance, and these insights can have specific implications for businesses. Let's discuss each metric's indication and its potential business impact:\n",
        "\n",
        "- Indication: Precision measures the accuracy of positive predictions made by the model. It answers the question: \"Of all the positive predictions made by the model, how many were actually correct?\"\n",
        "- Business Impact: High precision is crucial in situations where false positives are costly or detrimental to the business. For example, in a medical diagnosis application, high precision ensures that fewer healthy patients are mistakenly classified as having a disease, reducing unnecessary stress and medical costs.\n",
        "\n",
        "- Indication: Recall measures the model's ability to correctly identify all positive instances in the dataset. It answers the question: \"Of all the actual positive cases, how many did the model correctly identify?\"\n",
        "- Business Impact: High recall is essential when missing positive cases can have severe consequences. For instance, in fraud detection, high recall ensures that the majority of fraudulent transactions are caught, minimizing financial losses for the business.\n",
        "\n",
        "- Indication: F1-Score is the harmonic mean of precision and recall, providing a balanced measure that considers both false positives and false negatives.\n",
        "- Business Impact: F1-Score is valuable when a balance between precision and recall is needed. It helps businesses strike the right trade-off between false positives and false negatives based on their specific priorities.\n",
        "\n",
        "d) Accuracy:\n",
        "\n",
        "c) F1-Score:\n",
        "\n",
        "b) Recall:\n",
        "\n",
        "a) Precision:\n",
        "\n",
        "- Indication: Accuracy measures the overall correctness of the model's predictions across all classes.\n",
        "- Business Impact: High accuracy is generally desirable, but it can be misleading in imbalanced datasets. In such cases, where one class is rare, a high overall accuracy may hide poor performance in the minority class."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 SVM Classifier"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SVM Classifier\n",
        "model_svc = SVC()\n",
        "\n",
        "# fit the model\n",
        "model_svc.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "train_preds_svc = model_svc.predict(X_train)\n",
        "test_preds_svc = model_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# Get the accuracy scores\n",
        "train_svc_accuracy = accuracy_score(train_preds_svc,y_train)\n",
        "test_svc_accuracy = accuracy_score(test_preds_svc,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_svc_accuracy)\n",
        "print(\"The accuracy on test data is \", test_svc_accuracy)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the Predicted vs Actual Graph\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plotting the predicted values for the specific range\n",
        "plt.plot(test_preds_svc[100:200],label=\"Predicted\",color='limegreen')\n",
        "\n",
        "\n",
        "# Plotting the actual values for the specific range\n",
        "plt.plot(np.array(y_test[100:200]),label=\"Actual\",color='black')\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"Actual vs. Predicted Values (SVM Classifier)\")\n",
        "plt.xlabel(\"Data Points\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FxJMa0rXyNQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix of Training Class\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_train_svc = confusion_matrix(y_train,train_preds_svc)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_train_svc, annot=True, fmt = 'd',ax = ax, cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Training Class Data',fontsize=15)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "EnhEWRzSyQVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the confusion matrix of Testing Class\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "confuse_matrix_test_svc = confusion_matrix(y_test,test_preds_svc)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(confuse_matrix_test_svc, annot=True, fmt = 'd',ax = ax, cmap='coolwarm')\n",
        "ax.set_xlabel('Predicted Labels',fontsize=15)\n",
        "ax.set_ylabel('Actual Labels',fontsize=15)\n",
        "ax.set_title('Confusion Matrix of Test Data',fontsize=15)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "XScTYKklyR6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(\"Training Data\")\n",
        "print(classification_report(y_train, train_preds_svc))\n",
        "print(\"\\n\")\n",
        "print(\"Testing Data\")\n",
        "print(classification_report(y_test, test_preds_svc))"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Support Vector Machine (SVM) is a powerful and versatile machine learning algorithm used for both classification and regression tasks. It's particularly well-suited for classification problems. The primary goal of an SVM is to find the optimal hyperplane that best separates data points belonging to different classes in a way that maximizes the margin between these classes."
      ],
      "metadata": {
        "id": "YbDYSdLFygdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "param_grid = {'C':[0.01,0.1,1],\n",
        "              'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_svc = SVC()\n",
        "svc_grid = GridSearchCV(estimator = model_svc,\n",
        "                       param_grid = param_grid,\n",
        "                       cv = 3,\n",
        "                       verbose=2,\n",
        "                       n_jobs = -1)\n",
        "\n",
        "svc_grid.fit(X_train,y_train)\n",
        "\n",
        "print(svc_grid.best_params_)\n",
        "print(svc_grid.best_score_)\n",
        ""
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "train_tuned_svc_preds = svc_grid.predict(X_train)\n",
        "test_tuned_svc_preds = svc_grid.predict(X_test)\n",
        "\n",
        "\n",
        "# Get the accuracy scores\n",
        "train_accuracy_tuned_svc = accuracy_score(train_tuned_svc_preds,y_train)\n",
        "test_accuracy_tuned_svc = accuracy_score(test_tuned_svc_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_tuned_svc)\n",
        "print(\"The accuracy on test data is \", test_accuracy_tuned_svc)"
      ],
      "metadata": {
        "id": "OK0bH00qyzEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Cross Validation on SVM Classifier Model\n",
        "scores=cross_val_score(model_svc,X_train,y_train,cv=10,scoring='roc_auc')\n",
        "cv_score=scores.mean()\n",
        "print(\"Cross Validation Score is: \",cv_score)"
      ],
      "metadata": {
        "id": "3bdnIj8dy8zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GridSearchCV is used as hyperparameter optimisation. The reason is that it exhaustively explores a given hyperparameter space to identify the perfect hyperparameter that would produce the greatest model performance."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualizing evaluation Metric Score chart after Hyperparameter Tuning\n",
        "print(\"Training Data\")\n",
        "print(classification_report(y_train, train_tuned_svc_preds))\n",
        "print(\"\\n\")\n",
        "print(\"Testing Data\")\n",
        "print(classification_report(y_test, test_tuned_svc_preds))"
      ],
      "metadata": {
        "id": "AMkD4gOKzIak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitely, we have seen an improvement in the accuracy score on test data compared to the earlier model used. The testing accuracy has increased to 86%, from 85% earlier."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of which evaluation metric to prioritize depends on the specific business problem and its associated costs and risks. Hence we should carefully consider these metrics to make informed decisions. High precision is valuable when minimizing false positives is critical, high recall is important when catching all positive cases is essential, and F1-Score provides a balanced perspective. High accuracy can be misleading in imbalanced datasets where a high overall accuracy may hide poor performance in the minority class. Thus, we should consider accuracy along with precision, recall, and F1-Score to assess model performance comprehensively."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of the best model should consider the specific goals and requirements of the project, the interpretability of the model, and potential business implications.\n",
        "\n",
        "Based on the provided metrics and considering the Accuracy score as a key criterion, the SVM Model appears to be the better choice for the final prediction model. It also has a higher Cross Validation score on the testing data compared to Random Forest Classifier."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "eli5 (Explain Like I'm 5) is the most commonly used model explainability tool to interpret the feature importance of a machine learning model."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eli5"
      ],
      "metadata": {
        "id": "87eYpYJE1Gnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# Linear Regression\n",
        "model_lr = LogisticRegression()\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "perm_importance_lr = PermutationImportance(model_lr, random_state=42).fit(X_test, y_test)\n",
        "\n",
        "# Random Forest Regressor\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "perm_importance_rf = PermutationImportance(model_rf, random_state=42).fit(X_test, y_test)\n",
        "\n",
        "# XGBoost Regressor\n",
        "model_svc = SVC()\n",
        "model_svc.fit(X_train, y_train)\n",
        "\n",
        "perm_importance_svc = PermutationImportance(model_svc, random_state=42).fit(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "19xcCeNNz6bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model\n",
        "print(\"Logistic Regression Model\")\n",
        "eli5.show_weights(perm_importance_lr, feature_names=X_test.columns.tolist())\n",
        "\n",
        "# Print model\n",
        "print(\"Random Forest Classifier Model\")\n",
        "eli5.show_weights(perm_importance_rf, feature_names=X_test.columns.tolist())\n",
        "\n",
        "# Print model\n",
        "print(\"SVM Classifier Model\")\n",
        "eli5.show_weights(perm_importance_svc, feature_names=X_test.columns.tolist())"
      ],
      "metadata": {
        "id": "06lBoRtl0LTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "!pip install joblib\n",
        "import joblib\n",
        "\n",
        "#Random Forest Regressor model\n",
        "best_model = model_svc\n",
        "\n",
        "# Specify the file path to save the model\n",
        "model_filename = 'best_model_svc.joblib'\n",
        "\n",
        "# Save the model to the file\n",
        "joblib.dump(best_model, model_filename)\n",
        "\n",
        "print(f\"Model saved as {model_filename}\")"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "loaded_model = joblib.load(model_filename)\n",
        "# Now, you can use loaded_model for predictions"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, our exploration into the Airline Passenger Referral Prediction dataset has been a comprehensive and enlightening journey into the world of machine learning and predictive analytics. Utilizing the strengths of three distinct modelsâ€”Logistic Regression, SVM Classifier, and Random Forestâ€”we have effectively addressed the challenge of predicting passenger referrals, a crucial aspect in enhancing airline operations and passenger experiences.\n",
        "\n",
        "Key insights from this project include:\n",
        "\n",
        "Logistic Regression: This model served as a robust starting point for our analysis, offering simplicity and interpretability. It provided valuable insights into how various factors influence passenger referrals, aiding in informed decision-making.\n",
        "\n",
        "SVM Classifier: The SVM Classifier demonstrated its prowess in handling complex relationships within the data. Its ability to identify intricate patterns that simpler models might overlook resulted in high predictive accuracy.\n",
        "\n",
        "Random Forest: The Random Forest model, a collection of decision trees, excelled in both predictive accuracy and feature importance. Its ability to model non-linear relationships and highlight key drivers of passenger referrals made it an invaluable tool in this project.\n",
        "\n",
        "The combination of these three models not only improved the predictive accuracy of our system but also offered a comprehensive understanding of the factors influencing passenger referrals. This knowledge is vital for airlines in refining their strategies, enhancing customer interactions, and ultimately improving their services.\n",
        "\n",
        "Moreover, the insights gained from this classification project extend beyond the airline industry. The methodologies used and lessons learned can be applied to various sectors where classification and predictive modeling are key components of decision-making.\n",
        "\n",
        "In summary, our classification project on the Airline Passenger Referral Prediction dataset has provided us with the necessary tools and insights to tackle complex prediction tasks. It highlights the importance of model diversity in achieving optimal results and stands as a testament to the power of data-driven decision-making in improving operational efficiency and customer satisfaction in the airline industry and beyond."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}